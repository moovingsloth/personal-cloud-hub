import streamlit as st
from openai import OpenAI
import base64
import io
from PIL import Image
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="RTX 3090 AI Client", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– RTX 3090 AI Client (Web)")
st.markdown("Cloud Run Gatewayë¥¼ í†µí•´ ì§‘ ì•ˆì˜ **RTX 3090 (Qwen2.5-VL)** ì™€ í†µì‹ í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    # [í•µì‹¬ ë³€ê²½] ì¿ ë²„ë„¤í‹°ìŠ¤ ë‚´ë¶€ ì„œë¹„ìŠ¤ DNSë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
    default_url = os.getenv("API_BASE_URL", "http://vllm-service:80/v1")
    base_url = st.text_input("API Base URL", value=default_url)
    api_key = st.text_input("API Key", value="EMPTY", type="password")
    model_name = st.text_input("Model Name", value="Qwen/Qwen2.5-VL-7B-Instruct")

    st.divider()

# ì´ë¯¸ì§€ ìµœì í™” í•¨ìˆ˜
def encode_image_optimized(image_file):
    with Image.open(image_file) as img:
        # (1) RGB ë³€í™˜
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")
            
        # (2) ë¦¬ì‚¬ì´ì§•
        max_size = 1024
        if max(img.size) > max_size:
            img.thumbnail((max_size, max_size))

        # (3) JPEG ì••ì¶•
        buffer = io.BytesIO()
        img.save(buffer, format="JPEG", quality=85)
        
        size_kb = buffer.tell() / 1024
        return base64.b64encode(buffer.getvalue()).decode('utf-8'), size_kb

# ë©”ì¸ UI
st.subheader("ğŸš€ í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ ì„ íƒ")
mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (Simple Test)", "ê³ ê¸‰ ëŒ€í™” (Advanced Chat)"], horizontal=True)

if mode == "ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (Simple Test)":
    st.info("1x1 í”½ì…€ ì´ë¯¸ì§€ë¥¼ ì „ì†¡í•˜ì—¬ ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    
    if st.button("í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Run Test)", type="primary"):
        client = OpenAI(base_url=base_url, api_key=api_key)
        
        # 1x1 í”½ì…€ ê²€ì€ ì 
        TINY_IMAGE = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+P+/HgAFhAJ/wlseKgAAAABJRU5ErkJggg=="
        
        try:
            with st.spinner("ğŸ”¬ ì´ˆì†Œí˜• ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ì¤‘..."):
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "ì´ ì‚¬ì§„ì˜ ìƒ‰ê¹”ì´ ë­ì•¼?"},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{TINY_IMAGE}"}},
                            ],
                        }
                    ],
                    max_tokens=15,
                )
            st.success(f"âœ… ì„±ê³µ! ì‘ë‹µ: {response.choices[0].message.content}")
            
            with st.expander("ìƒì„¸ ë¡œê·¸"):
                st.json(response.model_dump())
                
        except Exception as e:
            st.error(f"âŒ ì‹¤íŒ¨: {e}")

else:
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("1. ì…ë ¥ (Input)")
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒ)", type=["jpg", "jpeg", "png"])
        use_sample = st.checkbox("í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ ì‚¬ìš© (1x1 Pixel)", value=False)
        user_prompt = st.text_area("ì§ˆë¬¸ ì…ë ¥", value="ì´ ì´ë¯¸ì§€ì—ì„œ 'ë¬¼ì²´'ë¥¼ ì‹ë³„í•˜ê³  ê·¸ ì¢Œí‘œ(bounding box)ë¥¼ JSONìœ¼ë¡œ ì•Œë ¤ì¤˜.", height=150)
        
        send_btn = st.button("ğŸš€ ì „ì†¡ (Send)", type="primary")

    with col2:
        st.subheader("2. ê²°ê³¼ (Output)")
        output_container = st.empty()
        log_expander = st.expander("ğŸ“œ ì²˜ë¦¬ ë¡œê·¸ (Logs)", expanded=True)

    if send_btn:
        if not user_prompt:
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            client = OpenAI(base_url=base_url, api_key=api_key)
            
            messages = []
            content_list = [{"type": "text", "text": user_prompt}]
            
            try:
                with log_expander:
                    st.write("ğŸ”„ ì—°ê²° ì´ˆê¸°í™” ì¤‘...")
                    
                    image_payload = None
                    if uploaded_file:
                        st.write(f"ğŸ“¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘... ({uploaded_file.name})")
                        image_data, size_kb = encode_image_optimized(uploaded_file)
                        st.write(f"ğŸ“‰ ì´ë¯¸ì§€ ìµœì í™” ì™„ë£Œ: {size_kb:.2f} KBë¡œ ì „ì†¡")
                        image_payload = {"url": f"data:image/jpeg;base64,{image_data}"}
                    elif use_sample:
                        st.write("ğŸ§ª ìƒ˜í”Œ ì´ë¯¸ì§€(1x1 Pixel) ì‚¬ìš©")
                        TINY_IMAGE = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+P+/HgAFhAJ/wlseKgAAAABJRU5ErkJggg=="
                        image_payload = {"url": f"data:image/png;base64,{TINY_IMAGE}"}
                    else:
                        st.warning("âš ï¸ ì´ë¯¸ì§€ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë§Œ ì „ì†¡ë©ë‹ˆë‹¤.")

                    if image_payload:
                        content_list.append({
                            "type": "image_url", 
                            "image_url": image_payload
                        })
                    
                    messages.append({
                        "role": "user",
                        "content": content_list
                    })
                    
                    st.write("ğŸš€ RTX 3090ì—ê²Œ ìš”ì²­ ì „ì†¡...")
                    
                    response_stream = client.chat.completions.create(
                        model=model_name,
                        messages=messages,
                        max_tokens=1024,
                        stream=True
                    )
                    
                    st.write("âœ… ì‘ë‹µ ìˆ˜ì‹  ì‹œì‘!")

                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í‘œì‹œ
                full_response = ""
                for chunk in response_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        output_container.markdown(full_response + "â–Œ")
                
                output_container.markdown(full_response)
                
                with log_expander:
                    st.write("âœ… ì™„ë£Œ!")

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                with log_expander:
                    st.write(f"Error details: {e}")
